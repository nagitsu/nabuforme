\chapter{Conclusiones y Trabajo Futuro}

Como resultado final del proyecto se logró construir un corpus en idioma español de casi seis mil
millones de palabras, el cual resultó sumamente útil para la construcción de vectores de palabras.
Se desarrolló además una herramienta que permite, entre otras cosas, consultar el corpus generado,
utilizar dicho corpus (o un subconjunto de sus documentos) para entrenar y evaluar vectores de
palabras y controlar los distintos mecanismos para continuar agregando documentos al corpus de
manera continua. Es importante resaltar que todos los objetivos planteados al comienzo del proyecto
fueron alcanzados de forma satisfactoria.

Desde el punto de vista académico se tuvo la oportunidad de realizar una investigación profunda en
un área en pleno auge y desarrollo, como es la construcción, aplicación y evaluación de vectores
de palabras. Además, se logró investigar y aplicar muchas herramientas y técnicas para el
desarrollo de aplicaciones web, scraping de internet, extracción y almacenamiento de grandes
cantidades de datos, etc. De esta manera, se logró elaborar un proyecto que requirió aplicar de
forma integral una gran cantidad de experiencias y conocimientos adquiridos durante la carrera y
nuestra actividad profesional.

En las próximas secciones incluimos un compilado de las principales conclusiones obtenidas, junto
con una serie de propuestas y caminos para futuros trabajos en el área.

\section{Conclusiones}

Como era esperado, se logró comprobar la gran dificultad de trabajar con vectores de palabras. Entre
los principales desafíos se encuentra la necesidad de contar con un corpus masivo, lo cual en sí mismo
conlleva una serie de desafíos de implementación y almacenamiento. Cómo se pudo comprobar al
realizar el estudio de estado del arte, la construcción de corpus de gran tamaño continúa siendo un
problema abierto. En particular, es necesario un cuidadoso proceso de selección de fuentes y posterior
limpieza de los datos obtenidos para obtener buenos resultados al entrenar vectores con los mismos.

Además, una vez construido el corpus, se comprobó que el entrenamiento de los vectores, así como su
posterior evaluación, son tareas que requieren una gran capacidad de cómputo si se espera poder
realizarlas en tiempos razonables. Por otro lado, el almacenamiento de un corpus masivo y de los
vectores generados requiere también una considerable cantidad de espacio en disco. Ambos tipos de
capacidades requeridas superan las de una computadora de uso general.

Aun con servidores que cuenten con la capacidad requerida, el entrenamiento de un modelo vectorial de
palabras puede llevar varios días. Esto dificulta la posibilidad de probar la combinación de diferentes
hiperparámetros para encontrar el mejor resultado.

A pesar de todas las dificultades mencionadas, no cabe duda de que el campo de los vectores de palabras
es sumamente interesante. Recientemente se han escrito multitud de trabajos relacionados con resultados
prometedores y el área continua siendo objeto de una intensa y rica investigación, por lo cuál resulta un
tema de investigación muy atractivo con posibilidades reales para realizar contribuciones significativas.
Encontrar la técnica óptima para la construcción de vectores de palabras sigue siendo un problema abierto,
pero este parece ser el mejor camino para conectar el campo de \textit{deep learning} al PLN\@.


\section{Trabajo Futuro}

Se identifican dos grandes caminos para extender y continuar lo realizado en el proyecto de
grado. El primero va por seguir las tareas de generación del corpus y de construcción de la
herramienta, mientras que el segundo por continuar la línea de investigación identificada durante el
relevamiento del estado del arte y de la evaluación de los modelos vectoriales.


\paragraph{Corpus}

Respecto al corpus de texto construido, se obtuvo un tamaño muy satisfactorio, pero se podría
conseguir un volumen incluso mayor y con más variedad: se priorizó incluir fuentes de palabras
diversas con el objetivo de mostrar qué tipos de datos existen, pero para cada una de estas áreas es
posible recolectar aún más palabras.

La mayor parte del corpus generado consta de noticias, pero se podrían incluir libros de texto
(en~\cite{Berardi2015} los autores obtienen dos mil millones de palabras de libros en italiano, y en
el presente proyecto apenas se incluyeron libros), más literatura amateur, más subtítulos
(incluyendo películas demás de series), más foros (de distintas temáticas, se tomó un único sitio),
el resto de los portales de Wikimedia (como Wikilibros, Wikiviajes, y Wikicitas), y más documentos
oficiales (podrían buscarse parlamentos de otros países además de Uruguay).

Yendo más allá del español, se podría incluir texto en otros idiomas; todos los documentos que se
almacenaron se etiquetaron como texto en español, por lo que no sería necesario adaptar ninguna
parte del proyecto.


\paragraph{Herramienta}

La herramienta cumplió con los objetivos planteados originalmente, pero vemos muchas oportunidades
de mejora que podrían aumentar su versatilidad y utilidad en futuros proyectos.

Por un lado, por más que la arquitectura fue pensada con un enfoque distribuido que permite escalar
agregando más nodos trabajadores, presenta algunas debilidades que podrían hacerla menos robusta;
por ejemplo, la transferencia de modelos vectoriales y datos de entrenamiento entre nodos puede ser
un cuello de botella importante. Su comportamiento no ha sido evaluado en profundidad salvo por el
escenario donde se corrió, por lo que sería recomendable desplegar la aplicación en un cluster
dedicado y ponerla a prueba.

Otra funcionalidad de utilidad sería implementar un sistema de autenticación de usuarios que brinde
acceso común al corpus pero que permita mantener distintos conjuntos de modelos para cada
usuario. Dicho sistema permitiría también restringir el acceso a la herramienta para usuarios no
identificados, evitando así que un usuario malintencionado entre a la aplicación e interfiera con el
correcto funcionamiento (por ejemplo, entrenando miles de modelos vectoriales).

En cuanto a la administración de representaciones vectoriales, sería de gran utilidad poder dar de
alta y entrenar modelos masivamente pasando una lista de hiperparámetros a utilizar, en lugar de
crearlos de a uno como se hace en la actualidad. Se podría permitir, incluso, que dada una lista de
conjuntos de pruebas se busque el modelo que mejores resultados obtenga automáticamente, realizando
una exploración del espacio de hiperparámetros (claro está, acotado) y empleando validación cruzada
para evaluarlos, de manera similar al enfoque tomado por los autores en~\cite{Levy2015}.

Relacionado al último punto, sería bueno también agregar más opciones de evaluación, incluyendo
idealmente algún tipo de evaluación implícita para la cual valga la pena optimizar al máximo la
performance de los modelos vectoriales.

Por último, con el fin de evitar tener que descargar las representaciones vectoriales para hacer
pruebas básicas, sería bueno ofrecer más funcionalidades de introspección de las mismas permitiendo,
por ejemplo, probar analogías desde la misma aplicación web, de manera de hacer evaluaciones
cualitativas simples fácilmente. También se podría utilizar el algoritmo tSNE~\cite{tSNE} para
mostrar una visualización de algunas palabras comunes en el espacio de vectores.


\paragraph{Investigación}

A raíz de los resultados obtenidos en el proceso de evaluación realizado, surge la necesidad de
estudiar en mayor profundidad el comportamiento de los modelos vectoriales en los escenarios
particulares vistos en el proyecto. Por ejemplo, investigar qué es lo que hace que algunas
conjugaciones verbales sean más fáciles de recuperar que otras, si la cantidad de ocurrencias en el
corpus de entrenamiento es lo único que las afecta o si existe una propiedad inherente a las mismas
que disminuye su performance (como el hecho de ser una construcción gramatical más compleja en,
e.g., conjugaciones del subjuntivo).

Viendo también la influencia que tuvo el eliminar los tildes del corpus de entrenamiento en los
resultados obtenidos, el estudio de cómo tratar palabras polisémicas parecería ser una rama de
investigación con potencial para mejorar en gran medida la calidad de las representaciones
obtenidas.


Durante el relevamiento del estado del arte también se identificaron algunas líneas de investigación
más generales que resultarían muy interesantes de continuar. Una de ellas, planteada por los autores
en~\cite{Levy2014a}, es buscar mejoras en la factorización de la matriz PPMI de los modelos
estadísticos, pues ya se vio cómo las palabras con pocas ocurrencias (como conjugaciones verbales
menos comunes) obtienen representaciones inferiores, afectando la performance en las tareas de
analogías.

Otro punto a investigar, planteado en el capítulo 2, es la relación entre la evaluación implícita y
explícita de los modelos vectoriales, y ver hasta qué punto se transfiere el hecho de obtener buena
performance en tareas como las analogías a tareas de mayor complejidad y que usen los vectores como
parte de una solución de mayor porte.

Como última propuesta de investigación, y algo que se tocó brevemente durante el proceso evaluación,
es estudiar en mayor profundidad la viabilidad de emplear vectores preentrenados genéricos para
otras tareas de PLN, y ver qué tan inferiores éstos resultan comparando con vectores entrenados para
una tarea específica con, por ejemplo, texto del dominio particular.
